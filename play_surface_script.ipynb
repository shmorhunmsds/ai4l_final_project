{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc08cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# --- Read in Data using cuDF ---\n",
    "play_df = pd.read_csv('datasets/nfl-playing-surface-analytics/PlayList.csv')\n",
    "player_df = pd.read_csv('datasets/nfl-playing-surface-analytics/PlayerTrackData.csv')\n",
    "injury_df = pd.read_csv('datasets/nfl-playing-surface-analytics/InjuryRecord.csv')\n",
    "\n",
    "\n",
    "# --- Create Initial Game DataFrame ---\n",
    "game_df = play_df[['GameID', 'StadiumType', 'FieldType', 'Weather', 'Temperature']]\n",
    "game_df = game_df.drop_duplicates()\n",
    "game_df = game_df.reset_index(drop=True)\n",
    "\n",
    "# --- Define Vectorized Cleaning Functions ---\n",
    "\n",
    "def clean_weather_vectorized(df):\n",
    "    \"\"\"\n",
    "    Clean the 'Weather' column using vectorized operations.\n",
    "    Maps raw weather strings to standard categories and sets special conditions to None.\n",
    "    \"\"\"\n",
    "    # Define condition sets (as Python sets for fast membership checking)\n",
    "    cloudy_conditions = {\n",
    "        'Cloudy 50% change of rain', 'Hazy', 'Cloudy.', 'Overcast', 'Mostly Cloudy',\n",
    "        'Cloudy, fog started developing in 2nd quarter', 'Partly Cloudy',\n",
    "        'Mostly cloudy', 'Rain Chance 40%', ' Partly cloudy', 'Party Cloudy',\n",
    "        'Rain likely, temps in low 40s', 'Partly Clouidy', 'Cloudy, 50% change of rain',\n",
    "        'Mostly Coudy', '10% Chance of Rain', 'Cloudy, chance of rain', \n",
    "        '30% Chance of Rain', 'Cloudy, light snow accumulating 1-3\"', 'cloudy', \n",
    "        'Coudy', 'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "        'Cloudy fog started developing in 2nd quarter', 'Cloudy light snow accumulating 1-3\"',\n",
    "        'Cloudywith periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "        'Cloudy and cold', 'Cloudy and Cool', 'Partly cloudy'\n",
    "    }\n",
    "    clear_conditions = {\n",
    "        'Clear, Windy', 'Clear to Cloudy', 'Clear, highs to upper 80s', 'Clear and clear',\n",
    "        'Partly sunny', 'Clear skies', 'Sunny', 'Partly Sunny', 'Mostly Sunny',\n",
    "        'Clear Skies', 'Sunny Skies', 'Partly clear', 'Fair', 'Sunny, highs to upper 80s',\n",
    "        'Sun & clouds', 'Mostly sunny', 'Sunny, Windy', 'Mostly Sunny Skies',\n",
    "        'Clear and Sunny', 'Clear and sunny', 'Clear to Partly Cloudy', 'Clear Skies',\n",
    "        'Clear and cold', 'Clear and warm', 'Clear and Cool', 'Sunny and cold',\n",
    "        'Sunny and warm', 'Sunny and clear'\n",
    "    }\n",
    "    rainy_conditions = {\n",
    "        'Rainy', 'Scattered Showers', 'Showers', 'Cloudy Rain', 'Light Rain', \n",
    "        'Rain shower', 'Rain likely, temps in low 40s.', 'Cloudy, Rain'\n",
    "    }\n",
    "    snow_conditions = {'Heavy lake effect snow'}\n",
    "    indoor_conditions = {'Controlled Climate', 'Indoors', 'N/A Indoor', 'N/A (Indoors)'}\n",
    "    \n",
    "    # Perform vectorized conditional replacements on the Weather column\n",
    "    df['Weather'] = df['Weather']\\\n",
    "        .mask(df['Weather'].isin(cloudy_conditions), 'Cloudy')\\\n",
    "        .mask(df['Weather'].isin(indoor_conditions), 'Indoor')\\\n",
    "        .mask(df['Weather'].isin(clear_conditions), 'Clear')\\\n",
    "        .mask(df['Weather'].isin(rainy_conditions), 'Rain')\\\n",
    "        .mask(df['Weather'].isin(snow_conditions), 'Snow')\\\n",
    "        .mask(df['Weather'].isin(['Cloudy.', 'Heat Index 95', 'Cold']), None)\n",
    "    return df\n",
    "\n",
    "def clean_stadiumtype_vectorized(df):\n",
    "    \"\"\"\n",
    "    Clean the 'StadiumType' column using regex replacements and vectorized anomaly filtering.\n",
    "    \"\"\"\n",
    "    # Standardize common StadiumType misspellings/formats using regex\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace(\n",
    "        r'Oudoor|Outdoors|Ourdoor|Outddors|Outdor|Outside', 'Outdoor', regex=True\n",
    "    )\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace(\n",
    "        r'Indoors|Indoor, Roof Closed|Indoor, Open Roof', 'Indoor', regex=True\n",
    "    )\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace(\n",
    "        r'Closed Dome|Domed, closed|Domed, Open|Domed, open|Dome, closed|Domed', 'Dome', regex=True\n",
    "    )\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace(\n",
    "        r'Retr. Roof-Closed|Outdoor Retr Roof-Open|Retr. Roof - Closed|Retr. Roof-Open|Retr. Roof - Open|Retr. Roof Closed', \n",
    "        'Retractable Roof', regex=True\n",
    "    )\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace('Open', 'Outdoor', regex=False)\n",
    "    \n",
    "    # Remove anomalies by setting certain values to None\n",
    "    df['StadiumType'] = df['StadiumType'].mask(\n",
    "        df['StadiumType'].isin(['Bowl', 'Heinz Field', 'Cloudy']), None\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def clean_play_df(df):\n",
    "    \"\"\"\n",
    "    Clean the play-level DataFrame by standardizing 'StadiumType' and 'Weather' fields.\n",
    "    \"\"\"\n",
    "    df_cleaned = df.copy()  # Avoid in-place modifications\n",
    "    df_cleaned = clean_stadiumtype_vectorized(df_cleaned)\n",
    "    df_cleaned = clean_weather_vectorized(df_cleaned)\n",
    "    return df_cleaned\n",
    "\n",
    "# --- Clean the Play DataFrame ---\n",
    "play_df_cleaned = clean_play_df(play_df)\n",
    "\n",
    "# Create a cleaned game-level DataFrame\n",
    "game_df_cleaned = play_df_cleaned[['GameID', 'StadiumType', 'FieldType', 'Weather', 'Temperature']]\n",
    "game_df_cleaned = game_df_cleaned.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# --- Join Game Data with Injury Data ---\n",
    "game_injury_df = injury_df.set_index('GameID').join(\n",
    "    game_df_cleaned.set_index('GameID'), how='outer'\n",
    ")\n",
    "\n",
    "# --- Fill Missing Injury Columns and Adjust Metrics ---\n",
    "for col in ['DM_M1', 'DM_M7', 'DM_M28', 'DM_M42']:\n",
    "    game_injury_df[col] = game_injury_df[col].fillna(0).astype('int32')\n",
    "\n",
    "game_injury_df['DM_M1']  = game_injury_df['DM_M1']  - game_injury_df['DM_M7']\n",
    "game_injury_df['DM_M7']  = game_injury_df['DM_M7']  - game_injury_df['DM_M28']\n",
    "game_injury_df['DM_M28'] = game_injury_df['DM_M28'] - game_injury_df['DM_M42']\n",
    "\n",
    "game_injury_df['Injury'] = (\n",
    "    game_injury_df['DM_M1'] +\n",
    "    game_injury_df['DM_M7'] +\n",
    "    game_injury_df['DM_M28'] +\n",
    "    game_injury_df['DM_M42']\n",
    ")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "game_injury_df = game_injury_df.drop(columns=['Surface', 'PlayerKey', 'PlayKey'])\n",
    "\n",
    "# --- Create Dummy Variables for the Game-Injury Data ---\n",
    "game_injury_df_dummies = pd.get_dummies(game_injury_df, dummy_na=True, drop_first=True)\n",
    "if 'FieldType_nan' in game_injury_df_dummies.columns:\n",
    "    game_injury_df_dummies = game_injury_df_dummies.drop(columns=['FieldType_nan'])\n",
    "\n",
    "# --- Merge Play Data and Injury Data on 'PlayKey' ---\n",
    "play_injury_df = injury_df.dropna(subset=['PlayKey']).set_index('PlayKey').join(\n",
    "    play_df_cleaned.set_index('PlayKey'), how='outer', lsuffix='_left', rsuffix='_right'\n",
    ")\n",
    "\n",
    "for col in ['DM_M1', 'DM_M7', 'DM_M28', 'DM_M42']:\n",
    "    play_injury_df[col] = play_injury_df[col].fillna(0).astype('int32')\n",
    "\n",
    "play_injury_df['DM_M1']  = play_injury_df['DM_M1']  - play_injury_df['DM_M7']\n",
    "play_injury_df['DM_M7']  = play_injury_df['DM_M7']  - play_injury_df['DM_M28']\n",
    "play_injury_df['DM_M28'] = play_injury_df['DM_M28'] - play_injury_df['DM_M42']\n",
    "\n",
    "play_injury_df['Injury'] = (\n",
    "    play_injury_df['DM_M1'] +\n",
    "    play_injury_df['DM_M7'] +\n",
    "    play_injury_df['DM_M28'] +\n",
    "    play_injury_df['DM_M42']\n",
    ")\n",
    "\n",
    "play_injury_df = play_injury_df.drop(columns=['Surface'])\n",
    "\n",
    "# --- Create Dummy Variables for Play-Level Data ---\n",
    "play_injury_df_dummies = pd.get_dummies(\n",
    "    play_injury_df,\n",
    "    columns=['PlayType', 'PositionGroup'],\n",
    "    dummy_na=True,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# --- Create Motion-Aggregated DataFrame ---\n",
    "def create_motion_data_df(injury_df, play_df, player_df):\n",
    "    \"\"\"\n",
    "    Merge injury, play, and motion data. Compute new motion feature \"angle\" and aggregate motion metrics.\n",
    "    \"\"\"\n",
    "    # Avoid in-place modifications by copying player_df\n",
    "    player_df = player_df.copy()\n",
    "    player_df['angle'] = player_df['o'] - player_df['dir']\n",
    "    \n",
    "    # Compute grouped max and average metrics by PlayKey\n",
    "    grouped_max = player_df[['PlayKey', 'time', 'dir', 'dis', 'o', 's', 'angle']].groupby('PlayKey').max()\n",
    "    grouped_avg = player_df[['PlayKey', 'time', 'dir', 'dis', 'o', 's', 'angle']].groupby('PlayKey').mean()\n",
    "    \n",
    "    # Merge aggregated motion features back into play data\n",
    "    play_df = play_df.merge(\n",
    "        grouped_max.reset_index(), on='PlayKey'\n",
    "    ).merge(\n",
    "        grouped_avg.reset_index(), on='PlayKey', suffixes=('_max', '_avg')\n",
    "    )\n",
    "    \n",
    "    # Clean injury data and merge with play data\n",
    "    injury_df_cleaned = injury_df.drop(columns=['PlayerKey', 'GameID', 'BodyPart', 'Surface'])\n",
    "    merged_df = injury_df_cleaned.merge(play_df, on='PlayKey', how='outer').fillna(0)\n",
    "    return merged_df\n",
    "\n",
    "motion_df = create_motion_data_df(injury_df, play_df, player_df)\n",
    "\n",
    "# Automatically select injury columns and compute the overall injury flag\n",
    "injury_cols = [col for col in motion_df.columns if col.startswith('DM_M')]\n",
    "motion_df['Injury'] = motion_df[injury_cols].sum(axis=1)\n",
    "\n",
    "\n",
    "# Prepare the features (drop leakage columns)\n",
    "X = motion_df.drop(columns=[\n",
    "    'Injury', 'DM_M1', 'DM_M7', 'DM_M28', 'DM_M42', 'PlayKey', 'PlayerKey', 'GameID'\n",
    "])\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "X = pd.get_dummies(X, dummy_na=True, drop_first=True, dtype='int')\n",
    "\n",
    "# For a pandas DataFrame with some boolean columns:\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'bool':\n",
    "        X[col] = X[col].astype('int32')\n",
    "\n",
    "\n",
    "# 3. Prepare the binary target (0 = no injury, 1 = injury)\n",
    "y = motion_df['Injury'].copy()\n",
    "y_binary = y.copy()\n",
    "y_binary[y_binary > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8248528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
