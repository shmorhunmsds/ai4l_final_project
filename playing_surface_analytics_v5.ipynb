{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80131d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 14 22:01:06 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off |   00000000:01:00.0  On |                  Off |\n",
      "|  0%   49C    P0             65W /  450W |   19386MiB /  24564MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3809      G   /usr/bin/gnome-shell                          475MiB |\n",
      "|    0   N/A  N/A      4798      G   /opt/google/chrome/chrome                       6MiB |\n",
      "|    0   N/A  N/A      4828      G   /usr/bin/Xwayland                            2469MiB |\n",
      "|    0   N/A  N/A      4885      G   ...seed-version=20250411-130057.255000        497MiB |\n",
      "|    0   N/A  N/A      5669      G   ...erProcess --variations-seed-version        311MiB |\n",
      "|    0   N/A  N/A     18968      C   ...conda3/envs/rapids-25.02/bin/python        390MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import scipy.stats as ss\n",
    "\n",
    "# Load the cuDF magic (ensures pandas operations are accelerated when possible)\n",
    "%load_ext cudf.pandas\n",
    "\n",
    "# Use cuDF for GPU-accelerated DataFrame operations\n",
    "import cudf\n",
    "\n",
    "# --- Read in Data using cuDF ---\n",
    "play_df = cudf.read_csv('nfl-playing-surface-analytics/PlayList.csv')\n",
    "player_df = cudf.read_csv('nfl-playing-surface-analytics/PlayerTrackData.csv')\n",
    "injury_df = cudf.read_csv('nfl-playing-surface-analytics/InjuryRecord.csv')\n",
    "\n",
    "# Check if GPU is available\n",
    "!nvidia-smi\n",
    "\n",
    "# --- Create Initial Game DataFrame ---\n",
    "game_df = play_df[['GameID', 'StadiumType', 'FieldType', 'Weather', 'Temperature']]\n",
    "game_df = game_df.drop_duplicates()\n",
    "game_df = game_df.reset_index(drop=True)\n",
    "\n",
    "# --- Define Vectorized Cleaning Functions ---\n",
    "\n",
    "def clean_weather_vectorized(df):\n",
    "    \"\"\"\n",
    "    Clean the 'Weather' column using vectorized operations.\n",
    "    Maps raw weather strings to standard categories and sets special conditions to None.\n",
    "    \"\"\"\n",
    "    # Define condition sets (as Python sets for fast membership checking)\n",
    "    cloudy_conditions = {\n",
    "        'Cloudy 50% change of rain', 'Hazy', 'Cloudy.', 'Overcast', 'Mostly Cloudy',\n",
    "        'Cloudy, fog started developing in 2nd quarter', 'Partly Cloudy',\n",
    "        'Mostly cloudy', 'Rain Chance 40%', ' Partly cloudy', 'Party Cloudy',\n",
    "        'Rain likely, temps in low 40s', 'Partly Clouidy', 'Cloudy, 50% change of rain',\n",
    "        'Mostly Coudy', '10% Chance of Rain', 'Cloudy, chance of rain', \n",
    "        '30% Chance of Rain', 'Cloudy, light snow accumulating 1-3\"', 'cloudy', \n",
    "        'Coudy', 'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "        'Cloudy fog started developing in 2nd quarter', 'Cloudy light snow accumulating 1-3\"',\n",
    "        'Cloudywith periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n",
    "        'Cloudy and cold', 'Cloudy and Cool', 'Partly cloudy'\n",
    "    }\n",
    "    clear_conditions = {\n",
    "        'Clear, Windy', 'Clear to Cloudy', 'Clear, highs to upper 80s', 'Clear and clear',\n",
    "        'Partly sunny', 'Clear skies', 'Sunny', 'Partly Sunny', 'Mostly Sunny',\n",
    "        'Clear Skies', 'Sunny Skies', 'Partly clear', 'Fair', 'Sunny, highs to upper 80s',\n",
    "        'Sun & clouds', 'Mostly sunny', 'Sunny, Windy', 'Mostly Sunny Skies',\n",
    "        'Clear and Sunny', 'Clear and sunny', 'Clear to Partly Cloudy', 'Clear Skies',\n",
    "        'Clear and cold', 'Clear and warm', 'Clear and Cool', 'Sunny and cold',\n",
    "        'Sunny and warm', 'Sunny and clear'\n",
    "    }\n",
    "    rainy_conditions = {\n",
    "        'Rainy', 'Scattered Showers', 'Showers', 'Cloudy Rain', 'Light Rain', \n",
    "        'Rain shower', 'Rain likely, temps in low 40s.', 'Cloudy, Rain'\n",
    "    }\n",
    "    snow_conditions = {'Heavy lake effect snow'}\n",
    "    indoor_conditions = {'Controlled Climate', 'Indoors', 'N/A Indoor', 'N/A (Indoors)'}\n",
    "    \n",
    "    # Perform vectorized conditional replacements on the Weather column\n",
    "    df['Weather'] = df['Weather']\\\n",
    "        .mask(df['Weather'].isin(cloudy_conditions), 'Cloudy')\\\n",
    "        .mask(df['Weather'].isin(indoor_conditions), 'Indoor')\\\n",
    "        .mask(df['Weather'].isin(clear_conditions), 'Clear')\\\n",
    "        .mask(df['Weather'].isin(rainy_conditions), 'Rain')\\\n",
    "        .mask(df['Weather'].isin(snow_conditions), 'Snow')\\\n",
    "        .mask(df['Weather'].isin(['Cloudy.', 'Heat Index 95', 'Cold']), None)\n",
    "    return df\n",
    "\n",
    "def clean_stadiumtype_vectorized(df):\n",
    "    \"\"\"\n",
    "    Clean the 'StadiumType' column using regex replacements and vectorized anomaly filtering.\n",
    "    \"\"\"\n",
    "    # Standardize common StadiumType misspellings/formats using regex\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace(\n",
    "        r'Oudoor|Outdoors|Ourdoor|Outddors|Outdor|Outside', 'Outdoor', regex=True\n",
    "    )\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace(\n",
    "        r'Indoors|Indoor, Roof Closed|Indoor, Open Roof', 'Indoor', regex=True\n",
    "    )\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace(\n",
    "        r'Closed Dome|Domed, closed|Domed, Open|Domed, open|Dome, closed|Domed', 'Dome', regex=True\n",
    "    )\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace(\n",
    "        r'Retr. Roof-Closed|Outdoor Retr Roof-Open|Retr. Roof - Closed|Retr. Roof-Open|Retr. Roof - Open|Retr. Roof Closed', \n",
    "        'Retractable Roof', regex=True\n",
    "    )\n",
    "    df['StadiumType'] = df['StadiumType'].str.replace('Open', 'Outdoor', regex=False)\n",
    "    \n",
    "    # Remove anomalies by setting certain values to None\n",
    "    df['StadiumType'] = df['StadiumType'].mask(\n",
    "        df['StadiumType'].isin(['Bowl', 'Heinz Field', 'Cloudy']), None\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def clean_play_df(df):\n",
    "    \"\"\"\n",
    "    Clean the play-level DataFrame by standardizing 'StadiumType' and 'Weather' fields.\n",
    "    \"\"\"\n",
    "    df_cleaned = df.copy()  # Avoid in-place modifications\n",
    "    df_cleaned = clean_stadiumtype_vectorized(df_cleaned)\n",
    "    df_cleaned = clean_weather_vectorized(df_cleaned)\n",
    "    return df_cleaned\n",
    "\n",
    "# --- Clean the Play DataFrame ---\n",
    "play_df_cleaned = clean_play_df(play_df)\n",
    "\n",
    "# Create a cleaned game-level DataFrame\n",
    "game_df_cleaned = play_df_cleaned[['GameID', 'StadiumType', 'FieldType', 'Weather', 'Temperature']]\n",
    "game_df_cleaned = game_df_cleaned.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# --- Join Game Data with Injury Data ---\n",
    "game_injury_df = injury_df.set_index('GameID').join(\n",
    "    game_df_cleaned.set_index('GameID'), how='outer'\n",
    ")\n",
    "\n",
    "# --- Fill Missing Injury Columns and Adjust Metrics ---\n",
    "for col in ['DM_M1', 'DM_M7', 'DM_M28', 'DM_M42']:\n",
    "    game_injury_df[col] = game_injury_df[col].fillna(0).astype('int32')\n",
    "\n",
    "game_injury_df['DM_M1']  = game_injury_df['DM_M1']  - game_injury_df['DM_M7']\n",
    "game_injury_df['DM_M7']  = game_injury_df['DM_M7']  - game_injury_df['DM_M28']\n",
    "game_injury_df['DM_M28'] = game_injury_df['DM_M28'] - game_injury_df['DM_M42']\n",
    "\n",
    "game_injury_df['Injury'] = (\n",
    "    game_injury_df['DM_M1'] +\n",
    "    game_injury_df['DM_M7'] +\n",
    "    game_injury_df['DM_M28'] +\n",
    "    game_injury_df['DM_M42']\n",
    ")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "game_injury_df = game_injury_df.drop(columns=['Surface', 'PlayerKey', 'PlayKey'])\n",
    "\n",
    "# --- Create Dummy Variables for the Game-Injury Data ---\n",
    "game_injury_df_dummies = cudf.get_dummies(game_injury_df, dummy_na=True, drop_first=True)\n",
    "if 'FieldType_nan' in game_injury_df_dummies.columns:\n",
    "    game_injury_df_dummies = game_injury_df_dummies.drop(columns=['FieldType_nan'])\n",
    "\n",
    "# --- Merge Play Data and Injury Data on 'PlayKey' ---\n",
    "play_injury_df = injury_df.dropna(subset=['PlayKey']).set_index('PlayKey').join(\n",
    "    play_df_cleaned.set_index('PlayKey'), how='outer', lsuffix='_left', rsuffix='_right'\n",
    ")\n",
    "\n",
    "for col in ['DM_M1', 'DM_M7', 'DM_M28', 'DM_M42']:\n",
    "    play_injury_df[col] = play_injury_df[col].fillna(0).astype('int32')\n",
    "\n",
    "play_injury_df['DM_M1']  = play_injury_df['DM_M1']  - play_injury_df['DM_M7']\n",
    "play_injury_df['DM_M7']  = play_injury_df['DM_M7']  - play_injury_df['DM_M28']\n",
    "play_injury_df['DM_M28'] = play_injury_df['DM_M28'] - play_injury_df['DM_M42']\n",
    "\n",
    "play_injury_df['Injury'] = (\n",
    "    play_injury_df['DM_M1'] +\n",
    "    play_injury_df['DM_M7'] +\n",
    "    play_injury_df['DM_M28'] +\n",
    "    play_injury_df['DM_M42']\n",
    ")\n",
    "\n",
    "play_injury_df = play_injury_df.drop(columns=['Surface'])\n",
    "\n",
    "# --- Create Dummy Variables for Play-Level Data ---\n",
    "play_injury_df_dummies = cudf.get_dummies(\n",
    "    play_injury_df,\n",
    "    columns=['PlayType', 'PositionGroup'],\n",
    "    dummy_na=True,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# --- Create Motion-Aggregated DataFrame ---\n",
    "def create_motion_data_df(injury_df, play_df, player_df):\n",
    "    \"\"\"\n",
    "    Merge injury, play, and motion data. Compute new motion feature \"angle\" and aggregate motion metrics.\n",
    "    \"\"\"\n",
    "    # Avoid in-place modifications by copying player_df\n",
    "    player_df = player_df.copy()\n",
    "    player_df['angle'] = player_df['o'] - player_df['dir']\n",
    "    \n",
    "    # Compute grouped max and average metrics by PlayKey\n",
    "    grouped_max = player_df[['PlayKey', 'time', 'dir', 'dis', 'o', 's', 'angle']].groupby('PlayKey').max()\n",
    "    grouped_avg = player_df[['PlayKey', 'time', 'dir', 'dis', 'o', 's', 'angle']].groupby('PlayKey').mean()\n",
    "    \n",
    "    # Merge aggregated motion features back into play data\n",
    "    play_df = play_df.merge(\n",
    "        grouped_max.reset_index(), on='PlayKey'\n",
    "    ).merge(\n",
    "        grouped_avg.reset_index(), on='PlayKey', suffixes=('_max', '_avg')\n",
    "    )\n",
    "    \n",
    "    # Clean injury data and merge with play data\n",
    "    injury_df_cleaned = injury_df.drop(columns=['PlayerKey', 'GameID', 'BodyPart', 'Surface'])\n",
    "    merged_df = injury_df_cleaned.merge(play_df, on='PlayKey', how='outer').fillna(0)\n",
    "    return merged_df\n",
    "\n",
    "motion_df = create_motion_data_df(injury_df, play_df, player_df)\n",
    "\n",
    "# Automatically select injury columns and compute the overall injury flag\n",
    "injury_cols = [col for col in motion_df.columns if col.startswith('DM_M')]\n",
    "motion_df['Injury'] = motion_df[injury_cols].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e156547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare the features (drop leakage columns)\n",
    "X = motion_df.drop(columns=[\n",
    "    'Injury', 'DM_M1', 'DM_M7', 'DM_M28', 'DM_M42', 'PlayKey', 'PlayerKey', 'GameID'\n",
    "])\n",
    "\n",
    "# 2. One-hot encode categorical columns\n",
    "X = cudf.get_dummies(X, dummy_na=True, drop_first=True)\n",
    "\n",
    "# For a cuDF DataFrame with some boolean columns:\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'bool':\n",
    "        X[col] = X[col].astype('int32')\n",
    "\n",
    "\n",
    "# 3. Prepare the binary target (0 = no injury, 1 = injury)\n",
    "y = motion_df['Injury'].copy()\n",
    "y_binary = y.copy()\n",
    "y_binary[y_binary > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4812b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerDay</th>\n",
       "      <th>PlayerGame</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>PlayerGamePlay</th>\n",
       "      <th>time_max</th>\n",
       "      <th>dir_max</th>\n",
       "      <th>dis_max</th>\n",
       "      <th>o_max</th>\n",
       "      <th>s_max</th>\n",
       "      <th>angle_max</th>\n",
       "      <th>...</th>\n",
       "      <th>Position_WR</th>\n",
       "      <th>PositionGroup_DB</th>\n",
       "      <th>PositionGroup_DL</th>\n",
       "      <th>PositionGroup_LB</th>\n",
       "      <th>PositionGroup_OL</th>\n",
       "      <th>PositionGroup_QB</th>\n",
       "      <th>PositionGroup_RB</th>\n",
       "      <th>PositionGroup_SPEC</th>\n",
       "      <th>PositionGroup_TE</th>\n",
       "      <th>PositionGroup_WR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>29.8</td>\n",
       "      <td>337.87</td>\n",
       "      <td>0.48</td>\n",
       "      <td>267.03</td>\n",
       "      <td>2.94</td>\n",
       "      <td>265.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>27.5</td>\n",
       "      <td>353.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>315.08</td>\n",
       "      <td>3.18</td>\n",
       "      <td>260.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>36.8</td>\n",
       "      <td>357.78</td>\n",
       "      <td>0.35</td>\n",
       "      <td>358.20</td>\n",
       "      <td>2.94</td>\n",
       "      <td>314.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "      <td>35.6</td>\n",
       "      <td>359.97</td>\n",
       "      <td>0.46</td>\n",
       "      <td>302.26</td>\n",
       "      <td>1.83</td>\n",
       "      <td>299.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>25.5</td>\n",
       "      <td>357.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>356.69</td>\n",
       "      <td>1.49</td>\n",
       "      <td>295.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PlayerDay  PlayerGame  Temperature  PlayerGamePlay  time_max  dir_max  \\\n",
       "0          1           1           63               1      29.8   337.87   \n",
       "1          1           1           63              10      27.5   353.24   \n",
       "2          1           1           63              11      36.8   357.78   \n",
       "3          1           1           63              12      35.6   359.97   \n",
       "4          1           1           63              13      25.5   357.43   \n",
       "\n",
       "   dis_max   o_max  s_max  angle_max  ...  Position_WR  PositionGroup_DB  \\\n",
       "0     0.48  267.03   2.94     265.19  ...            0                 0   \n",
       "1     0.45  315.08   3.18     260.69  ...            0                 0   \n",
       "2     0.35  358.20   2.94     314.68  ...            0                 0   \n",
       "3     0.46  302.26   1.83     299.54  ...            0                 0   \n",
       "4     0.49  356.69   1.49     295.07  ...            0                 0   \n",
       "\n",
       "   PositionGroup_DL  PositionGroup_LB  PositionGroup_OL  PositionGroup_QB  \\\n",
       "0                 0                 0                 0                 1   \n",
       "1                 0                 0                 0                 1   \n",
       "2                 0                 0                 0                 1   \n",
       "3                 0                 0                 0                 1   \n",
       "4                 0                 0                 0                 1   \n",
       "\n",
       "   PositionGroup_RB  PositionGroup_SPEC  PositionGroup_TE  PositionGroup_WR  \n",
       "0                 0                   0                 0                 0  \n",
       "1                 0                   0                 0                 0  \n",
       "2                 0                   0                 0                 0  \n",
       "3                 0                   0                 0                 0  \n",
       "4                 0                   0                 0                 0  \n",
       "\n",
       "[5 rows x 161 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b80b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9996628761291504\n"
     ]
    }
   ],
   "source": [
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.metrics import accuracy_score\n",
    "from cuml.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y_binary, \n",
    "    test_size=0.2,     # 20% of data will be held out for testing\n",
    "    random_state=42,   # For reproducibility\n",
    "    shuffle=True       # Data is shuffled by default; can be set to False if needed\n",
    ")\n",
    "\n",
    "# Initialize and train a RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, n_streams=1,random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b810aae",
   "metadata": {},
   "source": [
    "## model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163f86cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[53374     0]\n",
      " [   18     5]]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "from cuml.metrics import confusion_matrix\n",
    "\n",
    "# Convert your test labels (y_test) and predictions (y_pred) to cupy arrays if they aren't already:\n",
    "y_true = cp.asarray(y_test)       # Assuming y_test is a cuDF Series\n",
    "y_pred = cp.asarray(rf.predict(X_test))  # rf is your trained model\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# If you prefer to see the matrix as a numpy array, you can call .get():\n",
    "print(\"Confusion Matrix:\\n\", cm.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4828e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
